{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 928025,
          "sourceType": "datasetVersion",
          "datasetId": 500970
        }
      ],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshanCV/ML-project/blob/main/Audio_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'urbansound8k:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F500970%2F928025%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240303%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240303T184013Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2a2b16a38c14a39dc73ad5c760822f8ac5e0d02cd2dbb789bf027759861e115cd4127f243eebbc6d668f9aecfce71864bb6bf551101c1d013e7d67d44ebfbca7ecd8ec72fc87ba02f672a884f61f3c37ae0f4ef9cb8b1cce87c9ce8fb065a34c48e7aa319c18c9eafae6121fe69b00e2f0d794cb4cbdf0d66cd889b00d80eb7e8c429c5ddfda931d56c0192a191346fcd9fe9973419f0e1073955831f37909dafb70859f00400a5a06bded5e9c16f7e2d8dc37dcf2c2ad9fb81d323b50ae29ab5cb3a562b5c18d4946edf9e104ed6283aa3656c77a653b86b5ded1ee08c624ff9267e2b1d390315a75457f9ab1dae8a57ad717d8a0475ba03f7507fab244fa86'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "g94BnwFqncU5",
        "outputId": "37fbfb91-ed04-4d84-9c1f-9f5a498142ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading urbansound8k, 6026232524 bytes compressed\n",
            "[==================================================] 6026232524 bytes downloaded\n",
            "Downloaded and uncompressed: urbansound8k\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WBty9wwOp-1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "# Data preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, librosa\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Visualization\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Model\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers, Sequential\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Suppressing warnings\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "63f8992b-8593-40b6-927a-517654eebd33",
        "_cell_guid": "6e3c12db-7785-4ba9-b5b1-d9509eb16c64",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:26:20.731661Z",
          "iopub.execute_input": "2024-03-03T17:26:20.73206Z",
          "iopub.status.idle": "2024-03-03T17:26:20.739295Z",
          "shell.execute_reply.started": "2024-03-03T17:26:20.73203Z",
          "shell.execute_reply": "2024-03-03T17:26:20.737929Z"
        },
        "trusted": true,
        "id": "-LCkgE97ncU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Data"
      ],
      "metadata": {
        "id": "01Ya7yLmncVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading meta data\n",
        "data = pd.read_csv('/kaggle/input/urbansound8k/UrbanSound8K.csv')\n",
        "audioPath = '/kaggle/input/urbansound8k'\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "_uuid": "c14c733a-4ba0-407d-934b-9ab31421a987",
        "_cell_guid": "6ee7a45e-8b95-457d-b2f5-a582f67f41bc",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:19:20.753731Z",
          "iopub.execute_input": "2024-03-03T17:19:20.754374Z",
          "iopub.status.idle": "2024-03-03T17:19:20.810933Z",
          "shell.execute_reply.started": "2024-03-03T17:19:20.754342Z",
          "shell.execute_reply": "2024-03-03T17:19:20.809941Z"
        },
        "trusted": true,
        "id": "lbJF_j77ncVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UrbanSound8K Dataset Overview\n",
        "\n",
        "The UrbanSound8K dataset provides a collection of audio excerpts from various urban environments. Each audio file is uniquely identified by its name, which follows a specific format : [fsID]-[classID]-[occurrenceID]-[sliceID].wav.\n",
        "\n",
        "- **fsID** : The Freesound ID of the recording from which this excerpt (slice) is taken.\n",
        "\n",
        "- **start and end** : The start and end times of the audio slice in the original Freesound recording.\n",
        "\n",
        "- **salience** : A subjective salience rating of the sound, where 1 represents foreground and 2 represents background.\n",
        "\n",
        "- **fold** : The fold number (1-10) to which this file has been allocated during cross-validation.\n",
        "\n",
        "- **classID** : A numeric identifier of the sound class, ranging from 0 to 9. The mapping of classID to sound classes is as follows :\n",
        "  - 0 : air_conditioner\n",
        "  - 1 : car_horn\n",
        "  - 2 : children_playing\n",
        "  - 3 : dog_bark\n",
        "  - 4 : drilling\n",
        "  - 5 : engine_idling\n",
        "  - 6 : gun_shot\n",
        "  - 7 : jackhammer\n",
        "  - 8 : siren\n",
        "  - 9 : street_music\n",
        "\n",
        "\n",
        "- **class** : The corresponding class name, such as air_conditioner, car_horn, children_playing, etc.\n",
        "\n",
        "This dataset is suitable for tasks related to audio classification and sound event recognition, offering a diverse collection of urban sounds for analysis and model training."
      ],
      "metadata": {
        "id": "iGYwKfDtncVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting count distribution of classes\n",
        "plt.figure(figsize = (10, 4))\n",
        "sns.countplot(y = data['class'], palette = 'viridis')\n",
        "plt.title('Distribution of Classes', fontsize = 16)\n",
        "plt.xlabel('Count', fontsize = 14)\n",
        "plt.ylabel('Class', fontsize = 14)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T17:19:28.833073Z",
          "iopub.execute_input": "2024-03-03T17:19:28.83451Z",
          "iopub.status.idle": "2024-03-03T17:19:29.215262Z",
          "shell.execute_reply.started": "2024-03-03T17:19:28.834464Z",
          "shell.execute_reply": "2024-03-03T17:19:29.214006Z"
        },
        "trusted": true,
        "id": "Vq2dGajrncVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying a random waveform and spectrogram\n",
        "\n",
        "# Randomly selecting a row\n",
        "row = data.sample(1).iloc[0]\n",
        "\n",
        "# Constructing file path\n",
        "audioFile = os.path.join(audioPath, 'fold' + str(row['fold']), row['slice_file_name'])\n",
        "\n",
        "# Loading audio file\n",
        "waveform, sampleRate = librosa.load(audioFile)\n",
        "\n",
        "# Displaying audio\n",
        "print(f\"Class : {row['class']}\\n\")\n",
        "ipd.display(ipd.Audio(waveform, rate = sampleRate))\n",
        "\n",
        "# Displaying waveform\n",
        "plt.figure(figsize = (15, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(waveform)\n",
        "plt.title('Waveform', fontsize = 16)\n",
        "plt.xlabel('Sample Index', fontsize = 12)\n",
        "plt.ylabel('Amplitude', fontsize = 12)\n",
        "\n",
        "# Displaying spectrogram\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.specgram(waveform, Fs = sampleRate)\n",
        "plt.title('Spectrogram', fontsize = 16)\n",
        "plt.xlabel('Time (s)', fontsize = 12)\n",
        "plt.ylabel('Frequency (Hz)', fontsize = 12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "5d81c6ef-11d1-4237-a019-33594e3ff13d",
        "_cell_guid": "b938c043-be19-4d28-a0c2-13b3f13ce023",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:19:33.378439Z",
          "iopub.execute_input": "2024-03-03T17:19:33.378824Z",
          "iopub.status.idle": "2024-03-03T17:19:45.808521Z",
          "shell.execute_reply.started": "2024-03-03T17:19:33.378793Z",
          "shell.execute_reply": "2024-03-03T17:19:45.807334Z"
        },
        "trusted": true,
        "id": "KsLncMrrncVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio Feature Extraction Methods\n",
        "\n",
        "When working with audio data, there are several methods for extracting meaningful features that can be used for various tasks such as audio classification. Here are three fundamental approaches :\n",
        "\n",
        "a) **Using MFCCs Data**\n",
        "   - This method involves extracting Mel-frequency cepstral coefficients (MFCCs) from the audio files. MFCCs capture the spectral characteristics of the sound, making them a popular choice for audio feature extraction.\n",
        "\n",
        "b) **Using Spectrogram Images**\n",
        "   - An alternative approach is to generate spectrogram images of the audio using the `melspectrogram` function in Librosa. These spectrogram images can then be treated as 2D data points, similar to how images are handled in computer vision tasks.\n",
        "\n",
        "c) **Combining Both Features**\n",
        "   - For a comprehensive representation, some approaches involve combining both MFCCs and spectrogram features. While this can potentially enhance the model's performance, it often requires more computational time for reading and extracting data.\n",
        "\n",
        "### Chosen Approach\n",
        "\n",
        "In this project, the chosen method for audio feature extraction is : **a) Using MFCCs Data**\n",
        "   - This approach is selected for its effectiveness in capturing essential audio characteristics, providing a suitable foundation for audio classification tasks. It strikes a balance between informative features and computational efficiency.\n",
        "\n",
        "Feel free to explore other methods based on your specific use case and computational resources."
      ],
      "metadata": {
        "id": "OHrJPTAWncVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data"
      ],
      "metadata": {
        "id": "fXfbOAJnncVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "To enhance the variety in the dataset and improve the model's robustness, you can perform data augmentation on the audio files. Feel free to uncomment the code below and execute it. This code applies pre-emphasis, time stretching, and adds noise to the audio waveforms."
      ],
      "metadata": {
        "_uuid": "2f7686da-3d94-4d3c-b79d-7d56c5217b04",
        "_cell_guid": "11e19efa-5e77-4a97-b1ad-60fd6ceecb42",
        "trusted": true,
        "id": "KaeumqoFncVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentData(waveform):\n",
        "    # Applying pre-emphasis\n",
        "    waveform = librosa.effects.preemphasis(waveform)\n",
        "\n",
        "    # Time stretching\n",
        "    if np.random.rand() < 0.5:\n",
        "        rate = np.random.uniform(0.8, 1.2)\n",
        "        waveform = librosa.effects.time_stretch(waveform, rate = rate)\n",
        "\n",
        "    # Adding noise\n",
        "    waveform += 0.01 * np.random.normal(size = waveform.shape)\n",
        "\n",
        "    return waveform"
      ],
      "metadata": {
        "_uuid": "8bac1652-9279-4d45-80ef-b6a0bbeb80a5",
        "_cell_guid": "7fbf6d59-e3a3-4954-822f-263e3725cd75",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:19:58.338598Z",
          "iopub.execute_input": "2024-03-03T17:19:58.339302Z",
          "iopub.status.idle": "2024-03-03T17:19:58.345851Z",
          "shell.execute_reply.started": "2024-03-03T17:19:58.339266Z",
          "shell.execute_reply": "2024-03-03T17:19:58.344943Z"
        },
        "trusted": true,
        "id": "HVsZVxlKncVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Mel-frequency cepstral coefficients\n",
        "def mfccExtract(file):\n",
        "    # Loading audio file\n",
        "    waveform, sampleRate = librosa.load(file)\n",
        "\n",
        "    # waveform = augmentData(waveform)\n",
        "    features = librosa.feature.mfcc(y = waveform, sr = sampleRate, n_mfcc = 64)\n",
        "    return np.mean(features, axis = 1)"
      ],
      "metadata": {
        "_uuid": "102982ce-97c6-4c58-9864-faeadd9e9d09",
        "_cell_guid": "a98bff45-4972-4d2f-9c40-a144e6b71ecc",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:20:03.523853Z",
          "iopub.execute_input": "2024-03-03T17:20:03.524271Z",
          "iopub.status.idle": "2024-03-03T17:20:03.530777Z",
          "shell.execute_reply.started": "2024-03-03T17:20:03.524235Z",
          "shell.execute_reply": "2024-03-03T17:20:03.529582Z"
        },
        "trusted": true,
        "id": "E31ORWS-ncVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing mfcc features along with classes in dataframe\n",
        "extractAll = []\n",
        "\n",
        "# Iterating through each row\n",
        "for index, row in tqdm(data.iterrows()):\n",
        "    # Constructing file path\n",
        "    audioFile = os.path.join(audioPath, 'fold' + str(row['fold']), row['slice_file_name'])\n",
        "\n",
        "    # Extracting features and appending them\n",
        "    features = mfccExtract(audioFile)\n",
        "    extractAll.append([features, row['class']])"
      ],
      "metadata": {
        "_uuid": "4021bd2d-1616-49ee-8400-9ffbce209103",
        "_cell_guid": "65654fa1-f986-46d5-9c61-8465ae977e6d",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:20:06.690567Z",
          "iopub.execute_input": "2024-03-03T17:20:06.690971Z"
        },
        "trusted": true,
        "id": "nhLEQLe3ncVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresDf = pd.DataFrame(extractAll, columns = ['Features', 'Class'])\n",
        "featuresDf.head()"
      ],
      "metadata": {
        "_uuid": "b841f8d7-477e-4799-98ff-43298daa4a53",
        "_cell_guid": "f092ef34-7851-4f97-8f0e-0ad24331c324",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:28:05.20325Z",
          "iopub.execute_input": "2024-03-03T17:28:05.204999Z",
          "iopub.status.idle": "2024-03-03T17:28:05.234102Z",
          "shell.execute_reply.started": "2024-03-03T17:28:05.204913Z",
          "shell.execute_reply": "2024-03-03T17:28:05.233091Z"
        },
        "trusted": true,
        "id": "9RQgYpbuncVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting features into numpy array\n",
        "x = np.array(featuresDf['Features'].tolist())\n",
        "\n",
        "# Encoding classes\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(featuresDf['Class'])\n",
        "y = to_categorical(y, num_classes = 10)"
      ],
      "metadata": {
        "_uuid": "4f72db00-2018-4105-961f-1e4f23c20e9e",
        "_cell_guid": "e35080ca-8448-43ad-b626-f91d0377a3f6",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:28:19.751976Z",
          "iopub.execute_input": "2024-03-03T17:28:19.752675Z",
          "iopub.status.idle": "2024-03-03T17:28:19.768621Z",
          "shell.execute_reply.started": "2024-03-03T17:28:19.752639Z",
          "shell.execute_reply": "2024-03-03T17:28:19.767337Z"
        },
        "trusted": true,
        "id": "emmmwH61ncVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation split\n",
        "trainX, testX, trainY, testY = train_test_split(x, y, stratify = y, random_state = 0)"
      ],
      "metadata": {
        "_uuid": "f5fc34b7-153e-4790-b4f3-463895158f46",
        "_cell_guid": "f54aad24-0af9-4974-89b2-03ba2faf03c5",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:28:37.902832Z",
          "iopub.execute_input": "2024-03-03T17:28:37.903629Z",
          "iopub.status.idle": "2024-03-03T17:28:37.990503Z",
          "shell.execute_reply.started": "2024-03-03T17:28:37.903592Z",
          "shell.execute_reply": "2024-03-03T17:28:37.989015Z"
        },
        "trusted": true,
        "id": "joQwVSIzncVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Model"
      ],
      "metadata": {
        "id": "BXCJPHMKncVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    layers.Dense(1024, activation = 'relu', input_shape = (64,)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(512, activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(256, activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(32, activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "# Defining optimizer, loss function, and metrics\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "_uuid": "1839a7c3-c991-497b-96ac-bd8600acd670",
        "_cell_guid": "fe13c736-b9ad-4979-89ed-de590e3d59f4",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:28:46.486402Z",
          "iopub.execute_input": "2024-03-03T17:28:46.487615Z",
          "iopub.status.idle": "2024-03-03T17:28:46.972442Z",
          "shell.execute_reply.started": "2024-03-03T17:28:46.487566Z",
          "shell.execute_reply": "2024-03-03T17:28:46.970106Z"
        },
        "trusted": true,
        "id": "Iwz2VRPHncVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding early stopping to avoid overfitting\n",
        "earlyStopping = EarlyStopping(\n",
        "    monitor = 'val_accuracy',\n",
        "    min_delta = 5e-4,\n",
        "    patience = 5,\n",
        "    restore_best_weights = True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T17:29:10.612997Z",
          "iopub.execute_input": "2024-03-03T17:29:10.613428Z",
          "iopub.status.idle": "2024-03-03T17:29:10.618978Z",
          "shell.execute_reply.started": "2024-03-03T17:29:10.613391Z",
          "shell.execute_reply": "2024-03-03T17:29:10.617707Z"
        },
        "trusted": true,
        "id": "Xm6bhHd8ncVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a learning rate annealer\n",
        "reduceLR = ReduceLROnPlateau(\n",
        "    monitor = 'val_accuracy',\n",
        "    factor = 0.5,\n",
        "    patience = 3,\n",
        "    min_lr = 1e-5\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T17:29:29.317699Z",
          "iopub.execute_input": "2024-03-03T17:29:29.318139Z",
          "iopub.status.idle": "2024-03-03T17:29:29.326991Z",
          "shell.execute_reply.started": "2024-03-03T17:29:29.318101Z",
          "shell.execute_reply": "2024-03-03T17:29:29.325723Z"
        },
        "trusted": true,
        "id": "O8IUrbgDncVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "history = model.fit(\n",
        "    trainX, trainY,\n",
        "    validation_data = (testX, testY),\n",
        "    epochs = 50,\n",
        "    callbacks = [earlyStopping, reduceLR]\n",
        ")"
      ],
      "metadata": {
        "_uuid": "b2597c99-6a33-4370-b62f-921c4dc84182",
        "_cell_guid": "5e62c3ed-3910-411f-be5a-34e41ab67f94",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:29:46.989219Z",
          "iopub.execute_input": "2024-03-03T17:29:46.989627Z",
          "iopub.status.idle": "2024-03-03T17:31:21.613238Z",
          "shell.execute_reply.started": "2024-03-03T17:29:46.989595Z",
          "shell.execute_reply": "2024-03-03T17:31:21.612045Z"
        },
        "trusted": true,
        "id": "jwKssjs5ncVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historyDf = pd.DataFrame(history.history)"
      ],
      "metadata": {
        "_uuid": "3a621efc-2fd1-4863-afd0-a7429471844d",
        "_cell_guid": "3659d0a4-c307-4130-8c06-92e5611f8bb4",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:34:23.391141Z",
          "iopub.execute_input": "2024-03-03T17:34:23.391569Z",
          "iopub.status.idle": "2024-03-03T17:34:23.398266Z",
          "shell.execute_reply.started": "2024-03-03T17:34:23.391536Z",
          "shell.execute_reply": "2024-03-03T17:34:23.396941Z"
        },
        "trusted": true,
        "id": "WPSQpF7pncVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training and validation loss\n",
        "historyDf.loc[:, ['loss', 'val_loss']].plot()"
      ],
      "metadata": {
        "_uuid": "e2813ade-2be4-437a-8170-6cfa6e9c7852",
        "_cell_guid": "1cd3b538-b118-4977-9eaa-4c55c5fe8a8b",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:34:26.633312Z",
          "iopub.execute_input": "2024-03-03T17:34:26.633679Z",
          "iopub.status.idle": "2024-03-03T17:34:26.910272Z",
          "shell.execute_reply.started": "2024-03-03T17:34:26.633649Z",
          "shell.execute_reply": "2024-03-03T17:34:26.909346Z"
        },
        "trusted": true,
        "id": "N4DXGwCEncVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training and validation accuracy\n",
        "historyDf.loc[:, ['accuracy', 'val_accuracy']].plot()"
      ],
      "metadata": {
        "_uuid": "78469fdf-5113-4eb0-9273-664402ba9468",
        "_cell_guid": "1eab52ef-aa92-4abb-a1a8-ab243a7dc514",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:34:33.547715Z",
          "iopub.execute_input": "2024-03-03T17:34:33.548501Z",
          "iopub.status.idle": "2024-03-03T17:34:33.774321Z",
          "shell.execute_reply.started": "2024-03-03T17:34:33.548464Z",
          "shell.execute_reply": "2024-03-03T17:34:33.773034Z"
        },
        "trusted": true,
        "id": "yB_vXIitncVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating model\n",
        "score = model.evaluate(testX, testY)[1] * 100\n",
        "print(f'Validation accuracy of model : {score:.2f}%')"
      ],
      "metadata": {
        "_uuid": "c3abce71-ddcd-48df-a558-00085600d42d",
        "_cell_guid": "5ecb6808-fda2-4913-a986-fb264b4c7963",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-03T17:34:40.355205Z",
          "iopub.execute_input": "2024-03-03T17:34:40.355606Z",
          "iopub.status.idle": "2024-03-03T17:34:40.657672Z",
          "shell.execute_reply.started": "2024-03-03T17:34:40.355575Z",
          "shell.execute_reply": "2024-03-03T17:34:40.656471Z"
        },
        "trusted": true,
        "id": "XbcMp4QMncVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix\n",
        "pred = np.argmax(model.predict(testX), axis = 1)\n",
        "true = np.argmax(testY, axis = 1)\n",
        "\n",
        "matrix = confusion_matrix(true, pred)\n",
        "\n",
        "plt.figure(figsize = (12, 6))\n",
        "sns.heatmap(matrix, annot = True, cbar = False, fmt = 'd', cmap = 'Blues', xticklabels = encoder.classes_, yticklabels = encoder.classes_)\n",
        "plt.title('Confusion Matrix', fontsize = 16)\n",
        "plt.xlabel('Predicted Class', fontsize = 14)\n",
        "plt.xticks(rotation = 30)\n",
        "plt.ylabel('True Class', fontsize = 14)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-03T17:34:45.72217Z",
          "iopub.execute_input": "2024-03-03T17:34:45.722612Z",
          "iopub.status.idle": "2024-03-03T17:34:46.758435Z",
          "shell.execute_reply.started": "2024-03-03T17:34:45.722579Z",
          "shell.execute_reply": "2024-03-03T17:34:46.75722Z"
        },
        "trusted": true,
        "id": "inzjvolIncVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load your own audio file\n",
        "your_audio_file = '/content/mixkit-city-traffic-ambience-2931.wav'\n",
        "\n",
        "# Step 2: Extract features from your audio file\n",
        "waveform, sampleRate = librosa.load(your_audio_file)\n",
        "features = mfccExtract(your_audio_file)\n",
        "\n",
        "# Step 3: Reshape the features and make predictions\n",
        "features = features.reshape(1, -1)  # Reshape features for model input\n",
        "prediction = model.predict(features)\n",
        "predicted_class = encoder.classes_[np.argmax(prediction)]\n",
        "\n",
        "print(\"Predicted class:\", predicted_class)\n"
      ],
      "metadata": {
        "id": "LNkLmOzh3ETL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}